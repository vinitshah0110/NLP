{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"The Challenge is to classify news items into 1 of 46 categories.","metadata":{}},{"cell_type":"code","source":"#pip install contractions","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:45:15.207728Z","iopub.execute_input":"2021-09-28T10:45:15.208512Z","iopub.status.idle":"2021-09-28T10:45:15.212875Z","shell.execute_reply.started":"2021-09-28T10:45:15.208446Z","shell.execute_reply":"2021-09-28T10:45:15.212140Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#Importing required libraries\nimport pandas as pd\nimport re\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nplt.style.use('seaborn')\nimport warnings\nwarnings.filterwarnings('ignore')\nimport contractions\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, f1_score\nfrom sklearn.pipeline import Pipeline\n\nimport spacy\nnlp = spacy.load('en_core_web_sm')","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:45:15.216970Z","iopub.execute_input":"2021-09-28T10:45:15.217268Z","iopub.status.idle":"2021-09-28T10:45:17.294593Z","shell.execute_reply.started":"2021-09-28T10:45:15.217233Z","shell.execute_reply":"2021-09-28T10:45:17.293554Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#pip install openpyxl","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:45:17.296160Z","iopub.execute_input":"2021-09-28T10:45:17.296490Z","iopub.status.idle":"2021-09-28T10:45:17.300741Z","shell.execute_reply.started":"2021-09-28T10:45:17.296452Z","shell.execute_reply":"2021-09-28T10:45:17.299594Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Read the dataset\ndata = pd.read_excel('../input/reuters/train.xlsx')\n#View the top rows\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:45:17.304261Z","iopub.execute_input":"2021-09-28T10:45:17.304546Z","iopub.status.idle":"2021-09-28T10:45:18.184609Z","shell.execute_reply.started":"2021-09-28T10:45:17.304515Z","shell.execute_reply":"2021-09-28T10:45:18.183734Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Print a concise summary of a DataFrame\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:45:18.185689Z","iopub.execute_input":"2021-09-28T10:45:18.185922Z","iopub.status.idle":"2021-09-28T10:45:18.207089Z","shell.execute_reply.started":"2021-09-28T10:45:18.185895Z","shell.execute_reply":"2021-09-28T10:45:18.206547Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Return a Series containing counts of unique values\ndata['class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:45:18.208135Z","iopub.execute_input":"2021-09-28T10:45:18.208383Z","iopub.status.idle":"2021-09-28T10:45:18.215551Z","shell.execute_reply.started":"2021-09-28T10:45:18.208357Z","shell.execute_reply":"2021-09-28T10:45:18.214662Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Show the counts of observations using bars\nplt.figure(figsize=(12,8))\nsns.countplot('class',data=data);","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:45:18.216939Z","iopub.execute_input":"2021-09-28T10:45:18.217523Z","iopub.status.idle":"2021-09-28T10:45:18.784905Z","shell.execute_reply.started":"2021-09-28T10:45:18.217483Z","shell.execute_reply":"2021-09-28T10:45:18.784107Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Text Normalization: When we normalize text, we attempt to reduce its randomness. This helps us to reduce the amount of different information that the computer has to deal with, and therefore improves efficiency. \\\nOperations: Text cleaning, Tokenization, Expand Contractions, Case Conversions, Remove Stopwords, Lemmatization and Stemming","metadata":{}},{"cell_type":"code","source":"#Expand Contractions\ndata.text = data.text.apply(lambda item: ' '.join([contractions.fix(word) for word in item.split()]) )\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:45:18.786244Z","iopub.execute_input":"2021-09-28T10:45:18.786584Z","iopub.status.idle":"2021-09-28T10:45:22.193974Z","shell.execute_reply.started":"2021-09-28T10:45:18.786555Z","shell.execute_reply":"2021-09-28T10:45:22.193276Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Remove Punctuations and Numbers\ndata.text = data.text.apply(lambda item: re.sub('[^a-zA-Z]',' ',str(item)))\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:45:22.194909Z","iopub.execute_input":"2021-09-28T10:45:22.195628Z","iopub.status.idle":"2021-09-28T10:45:22.589903Z","shell.execute_reply.started":"2021-09-28T10:45:22.195595Z","shell.execute_reply":"2021-09-28T10:45:22.589292Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#Remove Whitespace\ndata.text = data.text.apply(lambda item: re.sub(r\"\\s+\", \" \", item, flags=re.UNICODE))\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:45:22.590942Z","iopub.execute_input":"2021-09-28T10:45:22.591615Z","iopub.status.idle":"2021-09-28T10:45:22.990299Z","shell.execute_reply.started":"2021-09-28T10:45:22.591582Z","shell.execute_reply":"2021-09-28T10:45:22.989290Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"data.text = data.text.apply(lambda item: ' '.join([word for word in item.split() if not len(word)<3]) )\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:45:22.991705Z","iopub.execute_input":"2021-09-28T10:45:22.992110Z","iopub.status.idle":"2021-09-28T10:45:23.185527Z","shell.execute_reply.started":"2021-09-28T10:45:22.992069Z","shell.execute_reply":"2021-09-28T10:45:23.184748Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"stopwords = nlp.Defaults.stop_words\nstopwords.remove('not')\n\ndata.text = data.text.apply(lambda item: nlp(str(item)))\ndata.text = data.text.apply(lambda item: [words.lemma_ for words in item if not words in stopwords])\ndata.text = data.text.apply(lambda item: ' '.join([words for words in item]))\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:45:23.186591Z","iopub.execute_input":"2021-09-28T10:45:23.186814Z","iopub.status.idle":"2021-09-28T10:48:01.869094Z","shell.execute_reply.started":"2021-09-28T10:45:23.186790Z","shell.execute_reply":"2021-09-28T10:48:01.868430Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"x = data['text']\ny = data['class']","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:48:01.871299Z","iopub.execute_input":"2021-09-28T10:48:01.872059Z","iopub.status.idle":"2021-09-28T10:48:01.877284Z","shell.execute_reply.started":"2021-09-28T10:48:01.872013Z","shell.execute_reply":"2021-09-28T10:48:01.876407Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#The TfidfVectorizer will tokenize documents, learn the vocabulary and inverse document frequency weightings, and allow you to encode new documents\nvector = TfidfVectorizer()\nvx = vector.fit_transform(x)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:48:01.878265Z","iopub.execute_input":"2021-09-28T10:48:01.878648Z","iopub.status.idle":"2021-09-28T10:48:02.569533Z","shell.execute_reply.started":"2021-09-28T10:48:01.878620Z","shell.execute_reply":"2021-09-28T10:48:02.568390Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"xtrain,xtest,ytrain,ytest = train_test_split(vx,y,test_size=0.3,random_state=101)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:48:02.571114Z","iopub.execute_input":"2021-09-28T10:48:02.571545Z","iopub.status.idle":"2021-09-28T10:48:02.582864Z","shell.execute_reply.started":"2021-09-28T10:48:02.571499Z","shell.execute_reply":"2021-09-28T10:48:02.581880Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"accuracy = []\nf1 = []","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:48:02.584373Z","iopub.execute_input":"2021-09-28T10:48:02.584635Z","iopub.status.idle":"2021-09-28T10:48:02.590677Z","shell.execute_reply.started":"2021-09-28T10:48:02.584608Z","shell.execute_reply":"2021-09-28T10:48:02.589417Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"The word ‘Forest’ in the term suggests that it will contain a lot of trees. The algorithm contains a bundle of decision trees to make a classification. It works great when it comes to taking decisions on data by creating branches from a root, which are essentially the conditions present in the data, and providing an output known as a leaf. \\\nPros:\n1. It reduces overfitting in decision trees and helps to improve the accuracy\n2. It is flexible to both classification and regression problems\n3. It works well with both categorical and continuous values\n\nCons:\n1. It requires much computational power as well as resources as it builds numerous trees to combine their outputs. \n2. It also requires much time for training as it combines a lot of decision trees to determine the class.","metadata":{}},{"cell_type":"code","source":"random_forest = RandomForestClassifier(n_estimators=150)\nrandom_forest.fit(xtrain,ytrain)\npredictions = random_forest.predict(xtest)\n\naccuracy.append(accuracy_score(ytest,predictions))\nf1.append(f1_score(ytest,predictions,average='micro'))\n\nprint('Accuracy Score: ', accuracy_score(ytest,predictions))\nprint('F1 Score: ', f1_score(ytest,predictions,average='micro'))\nprint(classification_report(ytest,predictions))","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:48:02.591827Z","iopub.execute_input":"2021-09-28T10:48:02.592077Z","iopub.status.idle":"2021-09-28T10:48:30.572555Z","shell.execute_reply.started":"2021-09-28T10:48:02.592039Z","shell.execute_reply":"2021-09-28T10:48:30.571667Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"In the SVM algorithm, we plot each data item as a point in n-dimensional space (where n is a number of features you have) with the value of each feature being the value of a particular coordinate. Then, we perform classification by finding the hyper-plane that differentiates the two classes very well. \\\nPros:\n1. It works really well with a clear margin of separation\n2. It is effective in high dimensional spaces.\n\nCons:\n1. It doesn’t perform well when we have large data set because the required training time is higher\n2. It also doesn’t perform very well, when the data set has more noise i.e. target classes are overlapping","metadata":{}},{"cell_type":"code","source":"svm = SVC(kernel='linear')\nsvm.fit(xtrain,ytrain)\npredictions = svm.predict(xtest)\n\naccuracy.append(accuracy_score(ytest,predictions))\nf1.append(f1_score(ytest,predictions,average='micro'))\n\nprint('Accuracy Score: ', accuracy_score(ytest,predictions))\nprint('F1 Score: ', f1_score(ytest,predictions,average='micro'))\nprint(classification_report(ytest,predictions))","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:48:30.573905Z","iopub.execute_input":"2021-09-28T10:48:30.574117Z","iopub.status.idle":"2021-09-28T10:49:06.220590Z","shell.execute_reply.started":"2021-09-28T10:48:30.574094Z","shell.execute_reply":"2021-09-28T10:49:06.219676Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"naive = MultinomialNB(alpha=0)\nnaive.fit(xtrain,ytrain)\npredictions = naive.predict(xtest)\n\naccuracy.append(accuracy_score(ytest,predictions))\nf1.append(f1_score(ytest,predictions,average='micro'))\n\nprint('Accuracy Score: ', accuracy_score(ytest,predictions))\nprint('F1 Score: ', f1_score(ytest,predictions,average='micro'))\nprint(classification_report(ytest,predictions))","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:49:06.221638Z","iopub.execute_input":"2021-09-28T10:49:06.221869Z","iopub.status.idle":"2021-09-28T10:49:06.283386Z","shell.execute_reply.started":"2021-09-28T10:49:06.221843Z","shell.execute_reply":"2021-09-28T10:49:06.282558Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"mlp = MLPClassifier(hidden_layer_sizes=(200,200),activation='relu')\nmlp.fit(xtrain,ytrain)\npredictions = mlp.predict(xtest)\n\naccuracy.append(accuracy_score(ytest,predictions))\nf1.append(f1_score(ytest,predictions,average='micro'))\n\nprint('Accuracy Score: ', accuracy_score(ytest,predictions))\nprint('F1 Score: ', f1_score(ytest,predictions,average='micro'))\nprint(classification_report(ytest,predictions))","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:49:06.284513Z","iopub.execute_input":"2021-09-28T10:49:06.284712Z","iopub.status.idle":"2021-09-28T10:53:26.063997Z","shell.execute_reply.started":"2021-09-28T10:49:06.284690Z","shell.execute_reply":"2021-09-28T10:53:26.063204Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nax.barh(('Random Forest','SVM','Naive Bayes','MLP'),accuracy);\nplt.title('Accuracy Score Comparison')\nplt.xlabel('Accuracy Score')\nplt.ylabel('Algorithm')","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:53:26.065438Z","iopub.execute_input":"2021-09-28T10:53:26.065964Z","iopub.status.idle":"2021-09-28T10:53:26.294482Z","shell.execute_reply.started":"2021-09-28T10:53:26.065924Z","shell.execute_reply":"2021-09-28T10:53:26.293873Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nax.barh(('Random Forest','SVM','Naive Bayes','MLP'),f1,color=['r','g','b','black'],alpha=0.7)\nplt.title('F1 Score Comparison')\nplt.xlabel('F1 Score')\nplt.ylabel('Algorithm')","metadata":{"execution":{"iopub.status.busy":"2021-09-28T10:53:26.295786Z","iopub.execute_input":"2021-09-28T10:53:26.296576Z","iopub.status.idle":"2021-09-28T10:53:26.505953Z","shell.execute_reply.started":"2021-09-28T10:53:26.296542Z","shell.execute_reply":"2021-09-28T10:53:26.505096Z"},"trusted":true},"execution_count":22,"outputs":[]}]}