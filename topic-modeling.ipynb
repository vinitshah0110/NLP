{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Topic modeling provides methods for automatically organizing, understanding, searching, and summarizing large electronic archives. Topic Modeling in NLP seeks to find hidden semantic structure in documents.\\\nIt can help with the following:\n* discovering the hidden themes in the collection.\n* classifying the documents into the discovered themes.\n* using the classification to organize/summarize/search the documents.","metadata":{}},{"cell_type":"markdown","source":"Latent Dirichlet Allocation: It is one of the most popular topic modeling methods. Each document is made up of various words, and each topic also has various words belonging to it. The aim of LDA is to find topics a document belongs to, based on the words in it.\n\n1. Go through each document and randomly assign each word in the document to one of k topics (k is chosen beforehand).\n2. For each document d, go through each word w and compute: \n* p(topic t | document d): Tries to capture how many words belong to the topic t for a given document d. \n* p(word w| topic t): Tries to capture how many documents are in topic t because of word w.","metadata":{}},{"cell_type":"markdown","source":"**Use Case:** Mapping Customer Complaints into pre_defined Complaint Categories \n\nFlow: Gather Data -> Text Normalization -> Extract Topics LDA -> Classify Data","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nimport warnings\nwarnings.filterwarnings('ignore')\nimport spacy\nnlp = spacy.load('en_core_web_sm')\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nimport gensim\nfrom gensim.corpora import Dictionary\nfrom gensim.models import LdaModel,CoherenceModel\nimport pyLDAvis.gensim","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:41:34.583721Z","iopub.execute_input":"2021-10-07T07:41:34.584211Z","iopub.status.idle":"2021-10-07T07:41:36.690048Z","shell.execute_reply.started":"2021-10-07T07:41:34.584151Z","shell.execute_reply":"2021-10-07T07:41:36.689357Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/comcastcomplaints/comcast_fcc_complaints_2015.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:41:36.693520Z","iopub.execute_input":"2021-10-07T07:41:36.693850Z","iopub.status.idle":"2021-10-07T07:41:36.790388Z","shell.execute_reply.started":"2021-10-07T07:41:36.693822Z","shell.execute_reply":"2021-10-07T07:41:36.789356Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data.tail()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:41:36.791872Z","iopub.execute_input":"2021-10-07T07:41:36.792310Z","iopub.status.idle":"2021-10-07T07:41:36.810565Z","shell.execute_reply.started":"2021-10-07T07:41:36.792264Z","shell.execute_reply":"2021-10-07T07:41:36.809352Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data['Customer Complaint'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:41:36.813580Z","iopub.execute_input":"2021-10-07T07:41:36.814012Z","iopub.status.idle":"2021-10-07T07:41:36.826102Z","shell.execute_reply.started":"2021-10-07T07:41:36.813973Z","shell.execute_reply":"2021-10-07T07:41:36.825247Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"customize_stop_words = ['comcast', 'i', 'fcc', 'hello', 'service', 'services', 'issue', 'issues', 'problem', 'problems', 'xfinity', 'customer', 'complaint', '$']\nfor word in customize_stop_words:\n    nlp.vocab[word].is_stop = True\n    \ndef preprocess(text):\n    text = text.split('\\n')[0].lower()\n    doc = nlp(text)\n    temp = []\n    for word in doc:\n        # If it's not a stop word or punctuation mark, add it to our article!\n        if word.text != 'n' and not word.is_stop and not word.is_punct and not word.like_num:\n            # We add the lematized version of the word\n            temp.append(word.lemma_.lower())\n    return temp\n\n# Tokenize each complaint\ndocs = data['Description'].apply(lambda text: preprocess(text))","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:41:36.827333Z","iopub.execute_input":"2021-10-07T07:41:36.827827Z","iopub.status.idle":"2021-10-07T07:42:24.556568Z","shell.execute_reply.started":"2021-10-07T07:41:36.827787Z","shell.execute_reply":"2021-10-07T07:42:24.555529Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"docs","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:42:24.558177Z","iopub.execute_input":"2021-10-07T07:42:24.558557Z","iopub.status.idle":"2021-10-07T07:42:24.571976Z","shell.execute_reply.started":"2021-10-07T07:42:24.558514Z","shell.execute_reply":"2021-10-07T07:42:24.571030Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dictionary = Dictionary(docs)\nprint('Distinct words in initial documents:', len(dictionary))\n\n# Filter out words that occur less than 10 documents, or more than 40% of the documents.\ndictionary.filter_extremes(no_below=10, no_above=0.4)\nprint('Distinct words after removing rare and common words:', len(dictionary))","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:42:24.573578Z","iopub.execute_input":"2021-10-07T07:42:24.574133Z","iopub.status.idle":"2021-10-07T07:42:24.757694Z","shell.execute_reply.started":"2021-10-07T07:42:24.574062Z","shell.execute_reply":"2021-10-07T07:42:24.756703Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#id2word is an optional dictionary that maps the word_id to a token\ncorpus = [dictionary.doc2bow(doc) for doc in docs]\nnum_topics = 5\nmodel = gensim.models.LdaMulticore(corpus=corpus, num_topics=num_topics, id2word=dictionary, passes=20, workers=2)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:42:24.759166Z","iopub.execute_input":"2021-10-07T07:42:24.759680Z","iopub.status.idle":"2021-10-07T07:42:52.734529Z","shell.execute_reply.started":"2021-10-07T07:42:24.759638Z","shell.execute_reply":"2021-10-07T07:42:52.733152Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"for i in range(num_topics):\n    print('\\nTopic {}\\n'.format(str(i)))\n    for term, frequency in model.show_topic(i, topn=10):\n        print(u'{:20} {:.3f}'.format(term, round(frequency, 3)))","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:42:52.736373Z","iopub.execute_input":"2021-10-07T07:42:52.736749Z","iopub.status.idle":"2021-10-07T07:42:52.757225Z","shell.execute_reply.started":"2021-10-07T07:42:52.736707Z","shell.execute_reply":"2021-10-07T07:42:52.756033Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"top_labels = {0: 'Customer Services', 1:'Internet Speed', 2:'Data Caps', 3: 'Pricing', 4:'Billing'}","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:45:18.135740Z","iopub.execute_input":"2021-10-07T07:45:18.136197Z","iopub.status.idle":"2021-10-07T07:45:18.143805Z","shell.execute_reply.started":"2021-10-07T07:45:18.136158Z","shell.execute_reply":"2021-10-07T07:45:18.142136Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"vector = TfidfVectorizer(input='content', analyzer = 'word', lowercase=True, stop_words='english',tokenizer=preprocess)\ndesc = vector.fit_transform(data['Description']).toarray()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:45:18.468299Z","iopub.execute_input":"2021-10-07T07:45:18.468686Z","iopub.status.idle":"2021-10-07T07:46:07.096747Z","shell.execute_reply.started":"2021-10-07T07:45:18.468647Z","shell.execute_reply":"2021-10-07T07:46:07.095576Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from collections import OrderedDict\ndef get_doc_topic_dist(model, corpus, kwords=False): \n    '''\n    LDA transformation, for each doc only returns topics with non-zero weight\n    This function makes a matrix transformation of docs in the topic space.\n    \n    model: the LDA model\n    corpus: the documents\n    kwords: if True adds and returns the keys\n    '''\n    \n    keys = []\n    for d in corpus:\n        tmp = {i:0 for i in range(num_topics)}\n        tmp.update(dict(model[d]))\n        vals = list(OrderedDict(tmp).values())\n        if kwords:\n            keys += [np.asarray(vals).argmax()]\n\n    return keys","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:46:07.099187Z","iopub.execute_input":"2021-10-07T07:46:07.099621Z","iopub.status.idle":"2021-10-07T07:46:07.108393Z","shell.execute_reply.started":"2021-10-07T07:46:07.099577Z","shell.execute_reply":"2021-10-07T07:46:07.107030Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"features = vector.get_feature_names() #This will print feature names selected (terms selected) from the raw documents\nlda_keys= get_doc_topic_dist(model, corpus, True)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:46:07.109902Z","iopub.execute_input":"2021-10-07T07:46:07.110289Z","iopub.status.idle":"2021-10-07T07:46:08.336061Z","shell.execute_reply.started":"2021-10-07T07:46:07.110253Z","shell.execute_reply":"2021-10-07T07:46:08.335297Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"top_words = []\nfor n in range(len(desc)):\n    inds = np.int0(np.argsort(desc[n])[::-1][:5])\n    top_words += [', '.join([features[i] for i in inds])]\n    \ndata['Description Top Words'] = pd.DataFrame(top_words)\ndata['Topic'] = pd.DataFrame(lda_keys)\ndata.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:46:08.338423Z","iopub.execute_input":"2021-10-07T07:46:08.339280Z","iopub.status.idle":"2021-10-07T07:46:08.615041Z","shell.execute_reply.started":"2021-10-07T07:46:08.339236Z","shell.execute_reply":"2021-10-07T07:46:08.614071Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#Topic Coherence measures score a single topic by measuring the degree of semantic similarity between high scoring words in the topic. These measurements help \n#distinguish between topics that are semantically interpretable topics.\nCoherenceModel(model = model, texts = docs, dictionary = dictionary, coherence='c_v').get_coherence()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:46:08.616405Z","iopub.execute_input":"2021-10-07T07:46:08.616656Z","iopub.status.idle":"2021-10-07T07:46:09.619371Z","shell.execute_reply.started":"2021-10-07T07:46:08.616629Z","shell.execute_reply":"2021-10-07T07:46:09.618310Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"test = 'internet speed is slow, call customer service now!!'\ntokens = preprocess(test)\nmodel[dictionary.doc2bow(tokens)]","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:46:09.620976Z","iopub.execute_input":"2021-10-07T07:46:09.621277Z","iopub.status.idle":"2021-10-07T07:46:09.641701Z","shell.execute_reply.started":"2021-10-07T07:46:09.621240Z","shell.execute_reply":"2021-10-07T07:46:09.640539Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"pyLDAvis.enable_notebook()\npyLDAvis.gensim.prepare(model, corpus, dictionary)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T07:46:09.642998Z","iopub.execute_input":"2021-10-07T07:46:09.643273Z","iopub.status.idle":"2021-10-07T07:46:13.644560Z","shell.execute_reply.started":"2021-10-07T07:46:09.643237Z","shell.execute_reply":"2021-10-07T07:46:13.643710Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"The left panel displays different topics and the distance between them. The closer the topics are in meaning the closer they appear, the same goes for dissimilar topics. \n\nThe right panel, displays a bar chart representing  how frequent the term is in the corpus and how \"distinctive\" it is in distinguishing between different topics.","metadata":{}}]}